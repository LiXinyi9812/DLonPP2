# DLonPP2  
Deep learning has been used with the street-view imagery Place Pulse 2.0 to evaluate the perception of urban
space along six perceptual dimensions: safe, lively, beautiful, wealthy, boring, and depressing. Traditional
methods automatically extract feature representations from images through a convolutional neural network to
yield prediction. However, the formers are computationally intensive and do not take a priori into account the
semantic information from the panoptic segmentation scene. In light of this, we propose a lightweight solution
that quickly predicts the sense of urban space from the implied highly compressed segmentation feature vector
of the street-view images via deep/machine learning models. Our solution achieves an average accuracy of
about 62%, which is acceptable compared to the baseline result accuracy of 68%, and significantly reduces
the complexity of the data and the computational effort.
