Filename: /workspace/shared/DRAMAinPT_test_v10.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
   207    294.8 MiB    294.8 MiB           1   @profile
   208                                         def main(epoch,image_dir,csv_dir,outputdir,hdf5_path,t,workers,device,batch_size,img_w,img_h,test_iteration):
   209                                             #inspect GPU
   210    294.8 MiB      0.0 MiB           1       frame = inspect.currentframe()
   211    294.8 MiB      0.0 MiB           1       gpu_tracker = MemTracker(frame)
   212    301.2 MiB      6.3 MiB           1       gpu_tracker.track()
   213
   214                                             #prepare network
   215    301.2 MiB      0.0 MiB           1       print('DRAMAinPT_final starts!')
   216                                             #mynet = {'safe':MyNet().to(device),'lively':MyNet().to(device),'beautiful':MyNet().to(device),'wealthy':MyNet().to(device),'depressing':MyNet().to(device),'boring':MyNet().to(device)}
   217    301.6 MiB      0.4 MiB           1       mynet = [MyNet(),MyNet()]
   218   1406.8 MiB   1105.2 MiB           1       vgg_extra = create_vgg19('./vgg_extractor')
   219   1406.8 MiB      0.0 MiB           1       print('finish loading networks')
   220   2924.0 MiB   1517.2 MiB           1       vgg_extra.to(device)
   221
   222   2924.2 MiB      0.2 MiB           1       gpu_tracker.track()
   223
   224   2924.2 MiB      0.0 MiB           1       criterion = nn.CrossEntropyLoss()
   225   2924.2 MiB      0.0 MiB           1       optimizer_vgg = optim.SGD(vgg_extra.parameters(), lr=0.001, momentum=0.5)
   226   2924.2 MiB      0.0 MiB           1       optimizer_mynet = []
   227   2924.2 MiB      0.0 MiB           3       for net in mynet:
   228   2924.2 MiB      0.0 MiB           2           optimizer_mynet.append(optim.Adam(net.parameters(), lr=0.001))
   229
   230                                             #prepare data
   231   2924.8 MiB      0.5 MiB           1       data_loader_train,data_loader_test,data_loader_val,num_train,num_validation,num_test = get(csv_dir)#num is the number of training data
   232   2924.8 MiB      0.0 MiB           1       list_val_acc = {'safe':[],'lively':[]}
   233   2924.8 MiB      0.0 MiB           1       list_train_acc = {'safe':[],'lively':[]}
   234   2924.8 MiB      0.0 MiB           1       list_loss = {'safe':[],'lively':[]}
   235   2924.8 MiB      0.0 MiB           1       max_acc = {'safe':0,'lively':0}
   236   2924.8 MiB      0.0 MiB           1       acc_train = {'safe':0,'lively':0}
   237   2924.8 MiB      0.0 MiB           1       max_iterations = max(num_train.values())//batch_size
   238
   239   2924.8 MiB      0.0 MiB           2       data_loader_train_final = zip(data_loader_train['safe'], \
   240   2924.8 MiB      0.0 MiB           1                                     cycle(data_loader_train['lively']))
   241
   242
   243   2924.8 MiB      0.0 MiB           1       dic={0:'safe',1:'lively'}
   244                                             #train loop
   245   4168.4 MiB      0.0 MiB           2       for epo in range(epoch):
   246   2924.8 MiB      0.0 MiB           1           sum_loss = {'safe':0,'lively':0}
   247   4168.4 MiB    424.6 MiB          26           for iteration, img1img2target in enumerate(data_loader_train_final):
   248   4168.1 MiB      0.0 MiB          25               print('batch: ', iteration,'starts!')
   249   4168.4 MiB      0.0 MiB          75               for k in range(2):
   250   4168.2 MiB      0.0 MiB          50                   img1, img2, target = img1img2target[k]
   251
   252   4168.2 MiB      3.0 MiB          50                   gpu_tracker.track()
   253   4168.2 MiB      0.0 MiB          50                   img1, img2, target = img1.to(device),img2.to(device),target.to(device)
   254   4168.2 MiB      0.0 MiB          50                   print(img1.device, img2.device, target.device)
   255   4168.3 MiB      5.9 MiB          50                   gpu_tracker.track()
   256
   257   4168.3 MiB      0.0 MiB          50                   loss = 0.0
   258   4168.3 MiB      0.0 MiB          50                   optimizer_mynet[k].zero_grad()
   259   4168.3 MiB      0.0 MiB          50                   optimizer_vgg.zero_grad()
   260
   261   4168.3 MiB     -4.0 MiB          50                   gpu_tracker.track()
   262   4168.3 MiB    800.3 MiB          50                   feature = fusion(img1, img2,vgg_extra)
   263   4168.3 MiB      1.5 MiB          50                   gpu_tracker.track()
   264   4168.3 MiB      0.0 MiB          50                   mynet[k].to(device)
   265   4168.3 MiB      1.0 MiB          50                   gpu_tracker.track()
   266
   267   4168.3 MiB      0.2 MiB          50                   output,w = mynet[k](feature)
   268   4168.3 MiB      6.9 MiB          50                   loss = criterion(output,target.long())+10*torch.mean(torch.mul(w, w))#why +10*nd.mean(w**2)
   269   4168.3 MiB      0.1 MiB          50                   acc_tmp = evaluate_accuracy(output, target)
   270   4168.3 MiB      0.0 MiB          50                   acc_train[dic[k]] += acc_tmp
   271   4168.3 MiB      0.4 MiB          50                   print('epoch=', epo + 1, 'iteration=', iteration + 1, '/', max_iterations, 'loss of ', dic[k], '=', loss)
   272   4168.4 MiB      1.0 MiB          50                   gpu_tracker.track()
   273
   274   4168.4 MiB      1.5 MiB          50                   loss.backward()
   275   4168.4 MiB      0.2 MiB          50                   optimizer_vgg.step()
   276   4168.4 MiB      0.2 MiB          50                   optimizer_mynet[k].step()
   277   4168.4 MiB      0.0 MiB          50                   sum_loss[dic[k]]+=loss
   278   4168.4 MiB      0.7 MiB          50                   gpu_tracker.track()
   279
   280
   281
   282                                                 #         #summary accuracy
   283                                                 #         if iteration%test_iteration==test_iteration-1 or iteration== max_iterations-1:#after 4000 times or all ready train one epoch,start val
   284                                                 #             if iteration%test_iteration==test_iteration-1:
   285                                                 #                 list_train_acc[dic[k]].append(acc_train[dic[k]]/test_iteration)
   286                                                 #             else:
   287                                                 #                 list_train_acc[dic[k]].append(acc_train[dic[k]]/(max_iterations%test_iteration))
   288                                                 #
   289                                                 #             #validation
   290                                                 #             print('**********test on data_validation of attribute',dic[k],' start ************')
   291                                                 #             acc_train[dic[k]] = 0
   292                                                 #             accuracy_val = 0
   293                                                 #            #for times, img1img2target in enumerate(data_loader_val_final):
   294                                                 #             for times, (img1_val, img2_val, target_val) in enumerate(data_loader_val[dic[k]]):
   295                                                 #                 img1_val, img2_val, target_val = img1_val.to(device), img2_val.to(device), target_val.to(device)
   296                                                 #                 print(dic[k],img1_val.size(),img2_val.size(),target_val.size())
   297                                                 #                 val_feature = fusion(img1_val,img2_val,vgg_extra)
   298                                                 #                 val_output,_ = mynet[k](val_feature)
   299                                                 #                 print(dic[k], val_output)
   300                                                 #
   301                                                 #                 acc_tmp_val = evaluate_accuracy(val_output, target_val)
   302                                                 #                 accuracy_val += acc_tmp_val
   303                                                 #                 print('times= ',(times+1))
   304                                                 #             list_val_acc[dic[k]].append(accuracy_val/(times+1))
   305                                                 #             print('validation accuracy of ',dic[k], '=', accuracy_val/(times+1))
   306                                                 #             if accuracy_val/(times+1)>max_acc[dic[k]]:
   307                                                 #                 max_acc[dic[k]] = accuracy_val/(times+1)
   308                                                 #                 torch.save(vgg_extra.state_dict(), outputdir+'/'+'vgg_params')
   309                                                 #                 torch.save(mynet[k].state_dict(), outputdir+'/'+'mynet'+dic[k]+'_params')
   310                                                 #             #show changes
   311                                                 #             print('change of accuracy on data_train ' + str(dic[k]) + ':')
   312                                                 #             for i in list_train_acc[dic[k]]:
   313                                                 #                 print(i)
   314                                                 #             print('change of accuracy on data_validation '+str(dic[k])+':')
   315                                                 #             for i in list_val_acc[dic[k]]:
   316                                                 #                  print(i)
   317                                                 #             print('**********test on data_validation of attribute',dic[k],' finished ************')
   318                                                 #             print('\n')
   319                                                 #     print('batch: ', iteration, 'finished!')
   320                                                 #
   321                                                 # print('\n')
   322                                                 # print('epoch '+str(epo)+ ' finished, changes of losses as following: ')
   323                                                 # for j in sum_loss:
   324                                                 #     if max_iterations == 0:
   325                                                 #         continue
   326                                                 #     list_loss[j].append(sum_loss[j]/max_iterations)
   327                                                 #     print('change of loss '+str(j)+' every epoch:')
   328                                                 #     for i in list_loss[j]:
   329                                                 #         print(i)
   330
   331
   332                                             # #test
   333                                             # vgg_extra_test = models.vgg19(pretrained = False).to(device)
   334                                             # vgg_extra_test.load_state_dict(torch.load(outputdir+'/'+'vgg_params'))
   335                                             # vgg_extra_test.eval()
   336                                             # mynet_test = [MyNet().to(device),MyNet().to(device)]
   337                                             # #mynet_test= {'safe':MyNet().to(device),'lively':MyNet().to(device),'beautiful':MyNet().to(device),'wealthy':MyNet().to(device),'depressing':MyNet().to(device),'boring':MyNet().to(device)}
   338                                             # acc_test={'safe':0,'lively':0}
   339                                             #
   340                                             # for k in range(2):
   341                                             #     print('\n')
   342                                             #     print('**********test on data_test of attribute ', dic[k], ' start ************')
   343                                             #     times = 0
   344                                             #     mynet_test[k].load_state_dict(torch.load(outputdir + '/' + 'mynet' + dic[k] + '_params'))
   345                                             #     mynet_test[k].eval()
   346                                             #     for iteration, (img1, img2, target) in enumerate(data_loader_test[dic[k]]):
   347                                             #         img1, img2, target = img1.to(device), img2.to(device), target.to(device)
   348                                             #         print(target, dic[k])
   349                                             #         te_feature = fusion(img1, img2,vgg_extra_test)
   350                                             #         te_output,_ = mynet_test[k](te_feature)
   351                                             #         acc_tmp = evaluate_accuracy(te_output, target)
   352                                             #         acc_test[dic[k]] += acc_tmp
   353                                             #         times = times+1
   354                                             #         print('accuracy on data_test of attribtue',dic[k],':',acc_test[dic[k]]/times)
   355                                             #
   356                                             # #plot
   357                                             # plot_loss_accuracy(list_loss,list_train_acc,list_val_acc,epoch)
