We develop MFA model based on DRAMA architecture, and introduce the attention module (See article: https://link.springer.com/article/10.1007/s11432-019-2899-9). Besides,
we use the segmentation mask and semantic information as additional inputs.  
See the description and results of each experiment: https://docs.google.com/spreadsheets/d/1qT2n0jGtSuOBBJmNrJZMBBwQnKlU4APjAM2pmb-VSuo/edit?usp=sharing
The codes and saved models are in the foler with the same name on LIGER.
